{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import psycopg2 \n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0,parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scripts.visualization' from 'c:\\\\ML and DS Files\\\\Kifiya AI\\\\Kaim-week-2\\\\scripts\\\\visualization.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import scripts.data_loader, scripts.clean_and_transform, scripts.analysis_1, scripts.visualization, scripts.analysis_2, scripts.analysis_3\n",
    "reload(scripts.data_loader)\n",
    "reload(scripts.clean_and_transform)\n",
    "reload(scripts.analysis_1)\n",
    "reload(scripts.analysis_2)\n",
    "reload(scripts.analysis_3)\n",
    "reload(scripts.visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data_loader import DataLoader, LoadSqlData\n",
    "from scripts.clean_and_transform import DropNullRows, NullValueFiller, DropUndefined\n",
    "from scripts.analysis_1 import UserSessionAggregator, DataDescriber, VariableTransformer, MetricsAnalyzer, DispersionAnalyzer, PCAAnalyzer, HandsetAnalysis\n",
    "from scripts.analysis_2 import TelecomEngagementAnalysis, TelecomEngagementAnalysis_2\n",
    "from scripts.analysis_3 import TelecomAnalysis\n",
    "from scripts.visualization import UnivariateAnalyzer, BivariateAnalyzer, CorrelationAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from postgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bearer Id</th>\n",
       "      <th>Start</th>\n",
       "      <th>Start ms</th>\n",
       "      <th>End</th>\n",
       "      <th>End ms</th>\n",
       "      <th>Dur. (ms)</th>\n",
       "      <th>IMSI</th>\n",
       "      <th>MSISDN/Number</th>\n",
       "      <th>IMEI</th>\n",
       "      <th>Last Location Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Youtube DL (Bytes)</th>\n",
       "      <th>Youtube UL (Bytes)</th>\n",
       "      <th>Netflix DL (Bytes)</th>\n",
       "      <th>Netflix UL (Bytes)</th>\n",
       "      <th>Gaming DL (Bytes)</th>\n",
       "      <th>Gaming UL (Bytes)</th>\n",
       "      <th>Other DL (Bytes)</th>\n",
       "      <th>Other UL (Bytes)</th>\n",
       "      <th>Total UL (Bytes)</th>\n",
       "      <th>Total DL (Bytes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.311448e+19</td>\n",
       "      <td>4/4/2019 12:01</td>\n",
       "      <td>770.0</td>\n",
       "      <td>4/25/2019 14:35</td>\n",
       "      <td>662.0</td>\n",
       "      <td>1823652.0</td>\n",
       "      <td>2.082014e+14</td>\n",
       "      <td>3.366496e+10</td>\n",
       "      <td>3.552121e+13</td>\n",
       "      <td>9.16456699548519E+015</td>\n",
       "      <td>...</td>\n",
       "      <td>15854611.0</td>\n",
       "      <td>2501332.0</td>\n",
       "      <td>8198936.0</td>\n",
       "      <td>9656251.0</td>\n",
       "      <td>278082303.0</td>\n",
       "      <td>14344150.0</td>\n",
       "      <td>171744450.0</td>\n",
       "      <td>8814393.0</td>\n",
       "      <td>36749741.0</td>\n",
       "      <td>308879636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.311448e+19</td>\n",
       "      <td>4/9/2019 13:04</td>\n",
       "      <td>235.0</td>\n",
       "      <td>4/25/2019 8:15</td>\n",
       "      <td>606.0</td>\n",
       "      <td>1365104.0</td>\n",
       "      <td>2.082019e+14</td>\n",
       "      <td>3.368185e+10</td>\n",
       "      <td>3.579401e+13</td>\n",
       "      <td>L77566A</td>\n",
       "      <td>...</td>\n",
       "      <td>20247395.0</td>\n",
       "      <td>19111729.0</td>\n",
       "      <td>18338413.0</td>\n",
       "      <td>17227132.0</td>\n",
       "      <td>608750074.0</td>\n",
       "      <td>1170709.0</td>\n",
       "      <td>526904238.0</td>\n",
       "      <td>15055145.0</td>\n",
       "      <td>53800391.0</td>\n",
       "      <td>653384965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.311448e+19</td>\n",
       "      <td>4/9/2019 17:42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/25/2019 11:58</td>\n",
       "      <td>652.0</td>\n",
       "      <td>1361762.0</td>\n",
       "      <td>2.082003e+14</td>\n",
       "      <td>3.376063e+10</td>\n",
       "      <td>3.528151e+13</td>\n",
       "      <td>D42335A</td>\n",
       "      <td>...</td>\n",
       "      <td>19725661.0</td>\n",
       "      <td>14699576.0</td>\n",
       "      <td>17587794.0</td>\n",
       "      <td>6163408.0</td>\n",
       "      <td>229584621.0</td>\n",
       "      <td>395630.0</td>\n",
       "      <td>410692588.0</td>\n",
       "      <td>4215763.0</td>\n",
       "      <td>27883638.0</td>\n",
       "      <td>279807335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.311448e+19</td>\n",
       "      <td>4/10/2019 0:31</td>\n",
       "      <td>486.0</td>\n",
       "      <td>4/25/2019 7:36</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1321509.0</td>\n",
       "      <td>2.082014e+14</td>\n",
       "      <td>3.375034e+10</td>\n",
       "      <td>3.535661e+13</td>\n",
       "      <td>T21824A</td>\n",
       "      <td>...</td>\n",
       "      <td>21388122.0</td>\n",
       "      <td>15146643.0</td>\n",
       "      <td>13994646.0</td>\n",
       "      <td>1097942.0</td>\n",
       "      <td>799538153.0</td>\n",
       "      <td>10849722.0</td>\n",
       "      <td>749039933.0</td>\n",
       "      <td>12797283.0</td>\n",
       "      <td>43324218.0</td>\n",
       "      <td>846028530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.311448e+19</td>\n",
       "      <td>4/12/2019 20:10</td>\n",
       "      <td>565.0</td>\n",
       "      <td>4/25/2019 10:40</td>\n",
       "      <td>954.0</td>\n",
       "      <td>1089009.0</td>\n",
       "      <td>2.082014e+14</td>\n",
       "      <td>3.369980e+10</td>\n",
       "      <td>3.540701e+13</td>\n",
       "      <td>D88865A</td>\n",
       "      <td>...</td>\n",
       "      <td>15259380.0</td>\n",
       "      <td>18962873.0</td>\n",
       "      <td>17124581.0</td>\n",
       "      <td>415218.0</td>\n",
       "      <td>527707248.0</td>\n",
       "      <td>3529801.0</td>\n",
       "      <td>550709500.0</td>\n",
       "      <td>13910322.0</td>\n",
       "      <td>38542814.0</td>\n",
       "      <td>569138589.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bearer Id            Start  Start ms              End  End ms  \\\n",
       "0  1.311448e+19   4/4/2019 12:01     770.0  4/25/2019 14:35   662.0   \n",
       "1  1.311448e+19   4/9/2019 13:04     235.0   4/25/2019 8:15   606.0   \n",
       "2  1.311448e+19   4/9/2019 17:42       1.0  4/25/2019 11:58   652.0   \n",
       "3  1.311448e+19   4/10/2019 0:31     486.0   4/25/2019 7:36   171.0   \n",
       "4  1.311448e+19  4/12/2019 20:10     565.0  4/25/2019 10:40   954.0   \n",
       "\n",
       "   Dur. (ms)          IMSI  MSISDN/Number          IMEI  \\\n",
       "0  1823652.0  2.082014e+14   3.366496e+10  3.552121e+13   \n",
       "1  1365104.0  2.082019e+14   3.368185e+10  3.579401e+13   \n",
       "2  1361762.0  2.082003e+14   3.376063e+10  3.528151e+13   \n",
       "3  1321509.0  2.082014e+14   3.375034e+10  3.535661e+13   \n",
       "4  1089009.0  2.082014e+14   3.369980e+10  3.540701e+13   \n",
       "\n",
       "      Last Location Name  ...  Youtube DL (Bytes)  Youtube UL (Bytes)  \\\n",
       "0  9.16456699548519E+015  ...          15854611.0           2501332.0   \n",
       "1                L77566A  ...          20247395.0          19111729.0   \n",
       "2                D42335A  ...          19725661.0          14699576.0   \n",
       "3                T21824A  ...          21388122.0          15146643.0   \n",
       "4                D88865A  ...          15259380.0          18962873.0   \n",
       "\n",
       "   Netflix DL (Bytes)  Netflix UL (Bytes)  Gaming DL (Bytes)  \\\n",
       "0           8198936.0           9656251.0        278082303.0   \n",
       "1          18338413.0          17227132.0        608750074.0   \n",
       "2          17587794.0           6163408.0        229584621.0   \n",
       "3          13994646.0           1097942.0        799538153.0   \n",
       "4          17124581.0            415218.0        527707248.0   \n",
       "\n",
       "   Gaming UL (Bytes)  Other DL (Bytes)  Other UL (Bytes)  Total UL (Bytes)  \\\n",
       "0         14344150.0       171744450.0         8814393.0        36749741.0   \n",
       "1          1170709.0       526904238.0        15055145.0        53800391.0   \n",
       "2           395630.0       410692588.0         4215763.0        27883638.0   \n",
       "3         10849722.0       749039933.0        12797283.0        43324218.0   \n",
       "4          3529801.0       550709500.0        13910322.0        38542814.0   \n",
       "\n",
       "   Total DL (Bytes)  \n",
       "0       308879636.0  \n",
       "1       653384965.0  \n",
       "2       279807335.0  \n",
       "3       846028530.0  \n",
       "4       569138589.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your SQL query\n",
    "query = \"SELECT * FROM xdr_data\"\n",
    "# Create an instance of the LoadSqlData class\n",
    "data_loader = LoadSqlData(query)\n",
    "# Load data using psycopg2\n",
    "data= data_loader.load_data_using_sqlalchemy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150001, 55)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully droped undefined columns\n"
     ]
    }
   ],
   "source": [
    "# Drop  undefined values from Handset Type\n",
    "drop_undefined = DropUndefined(data)\n",
    "data = drop_undefined.DeleteUndefined(column='Handset Type', value='undefined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfuly dropped null rows from ['Bearer Id', 'Start', 'End', 'IMSI', 'MSISDN/Number', 'IMEI', 'Last Location Name', 'Handset Manufacturer', 'Handset Type']\n"
     ]
    }
   ],
   "source": [
    "# drop null rows for the follwing columns\n",
    "# Bearer Id, Start, End, IMSI, MSISDN/Number, IMEI,Last Location Name, Handset Manufacturer, Handset Type\n",
    "col_1 = ['Bearer Id', 'Start', 'End', 'IMSI', 'MSISDN/Number', 'IMEI', 'Last Location Name', 'Handset Manufacturer', 'Handset Type']\n",
    "dropper = DropNullRows(columns_to_check=col_1)\n",
    "\n",
    "# Drop rows where the specified column has null values\n",
    "data = dropper.drop_if_null(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns = ['Avg RTT DL (ms)', 'Avg RTT UL (ms)', 'TCP DL Retrans. Vol (Bytes)', 'TCP UL Retrans. Vol (Bytes)', \n",
    "           'DL TP < 50 Kbps (%)','50 Kbps < DL TP < 250 Kbps (%)', '250 Kbps < DL TP < 1 Mbps (%)', 'DL TP > 1 Mbps (%)', \n",
    "           'UL TP < 10 Kbps (%)','10 Kbps < UL TP < 50 Kbps (%)', '50 Kbps < UL TP < 300 Kbps (%)', 'UL TP > 300 Kbps (%)',\n",
    "            'HTTP DL (Bytes)', 'HTTP UL (Bytes)', 'Nb of sec with 125000B < Vol DL', 'Nb of sec with 1250B < Vol UL < 6250B',\n",
    "            'Nb of sec with 31250B < Vol DL < 125000B', 'Nb of sec with 37500B < Vol UL', 'Nb of sec with 6250B < Vol DL < 31250B',\n",
    "            'Nb of sec with 6250B < Vol UL < 37500B','Nb of sec with Vol DL < 6250B', 'Nb of sec with Vol UL < 1250B']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical null values are filled based on the outlier and normal distribution\n",
    "# Initialize the NullValueFiller class\n",
    "filler = NullValueFiller(data, null_columns)\n",
    "    \n",
    "# Fill null values based on mean/median decision\n",
    "filler.fill_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns are not null\n"
     ]
    }
   ],
   "source": [
    "null_counts = data.isnull().sum()\n",
    "if null_counts.sum() > 0:\n",
    "    print('Null value present please check the dataframe')\n",
    "else:\n",
    "    print('All columns are not null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script for analysis\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'telecom_data.csv'  # Replace with the actual dataset path\n",
    "    telecom_analysis = TelecomAnalysis(file_path)\n",
    "\n",
    "    # Preprocess data\n",
    "    telecom_analysis.preprocess_data()\n",
    "\n",
    "    # Task 1: Aggregate metrics per customer\n",
    "    aggregated_data = telecom_analysis.aggregate_per_customer()\n",
    "    print(\"Aggregated Data:\\n\", aggregated_data.head())\n",
    "\n",
    "    # Task 2: Compute top, bottom, and most frequent for metrics\n",
    "    for metric in ['TCP Retransmission', 'RTT', 'Throughput']:\n",
    "        top_10, bottom_10, frequent = telecom_analysis.compute_top_bottom_frequent(metric)\n",
    "        print(f\"Top 10 {metric}: {top_10}\")\n",
    "        print(f\"Bottom 10 {metric}: {bottom_10}\")\n",
    "        print(f\"Most Frequent {metric}: {frequent}\")\n",
    "\n",
    "    # Task 3: Distribution analysis\n",
    "    throughput_distribution = telecom_analysis.distribution_analysis('Throughput', 'Handset Type')\n",
    "    print(\"Throughput Distribution:\\n\", throughput_distribution.head())\n",
    "\n",
    "    tcp_distribution = telecom_analysis.distribution_analysis('TCP Retransmission', 'Handset Type')\n",
    "    print(\"TCP Retransmission Distribution:\\n\", tcp_distribution.head())\n",
    "\n",
    "    # Task 4: K-means clustering\n",
    "    features = ['TCP Retransmission', 'RTT', 'Throughput']\n",
    "    cluster_data, cluster_centers = telecom_analysis.kmeans_clustering(features)\n",
    "    print(\"Cluster Data:\\n\", cluster_data.head())\n",
    "    print(\"Cluster Centers:\\n\", cluster_centers)\n",
    "\n",
    "    # Visualize clusters\n",
    "    plt.scatter(telecom_analysis.data['TCP Retransmission'], telecom_analysis.data['Throughput'], c=telecom_analysis.data['Cluster'])\n",
    "    plt.title(\"Clusters Visualization\")\n",
    "    plt.xlabel(\"TCP Retransmission\")\n",
    "    plt.ylabel(\"Throughput\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "z_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
